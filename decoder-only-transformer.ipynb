{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7ef725",
   "metadata": {},
   "source": [
    "![We only build the decoder aspect](https://heidloff.net/assets/img/2023/02/transformers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c1ef592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27163d",
   "metadata": {},
   "source": [
    "### Set Up Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8eae8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the vocabulary to include new tokens\n",
    "token_to_id = {\n",
    "    'Lebron': 0, \n",
    "    'James': 1, \n",
    "    'is': 2, \n",
    "    'the': 3, \n",
    "    'Greatest': 4, \n",
    "    'OAT': 5, \n",
    "    '<EOS>': 6\n",
    "}\n",
    "\n",
    "# Input Tensor\n",
    "inputs = torch.tensor([\n",
    "    [token_to_id[\"Lebron\"], \n",
    "    token_to_id[\"James\"], \n",
    "    token_to_id[\"is\"], \n",
    "    token_to_id[\"the\"], \n",
    "    token_to_id[\"Greatest\"], \n",
    "    token_to_id[\"<EOS>\"]\n",
    "]])\n",
    "\n",
    "# Output Tensor: Expected next token\n",
    "labels = torch.tensor([\n",
    "    [token_to_id[\"James\"], \n",
    "    token_to_id[\"is\"], \n",
    "    token_to_id[\"the\"], \n",
    "    token_to_id[\"Greatest\"], \n",
    "    token_to_id[\"OAT\"], \n",
    "    token_to_id[\"<EOS>\"]\n",
    "]])\n",
    "\n",
    "id_to_token = dict(map(reversed, token_to_id.items()))\n",
    "\n",
    "\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd5212",
   "metadata": {},
   "source": [
    "### Position Encoding\n",
    "\n",
    "Uses a sequence of alternating sine and cosine waves\n",
    "\n",
    "Example:\n",
    "\n",
    "PE = sin(pos/10000)\n",
    "\n",
    "PE = cos(pos/10000)\n",
    "\n",
    "**Equations**:\n",
    "\n",
    "PE = sin(pos/10000^(2i/d))\n",
    "\n",
    "PE = cos(pos/10000&(2i/d))\n",
    "\n",
    "Let i be the embedding position(changes every 2) and pos be the token position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f03ba23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEncoding(nn.Module):\n",
    "    def __init__(self, d_model=2, max_len=6): \n",
    "        #d_model: # of Word-embedding values per token\n",
    "        #max_len: max # of tokens out transformer can process\n",
    "        \n",
    "        super().__init__()\n",
    "        # Position Encoding Matrix of 0's(6x2)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # This would be a pos column matrix. if max_len = 2: [0,1]\n",
    "        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n",
    "        # This would be our i term:\n",
    "        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n",
    "        \n",
    "        # This term would be the denominator of the whats in the sine function\n",
    "        div_term = 1/torch.tensor(10000.0)**(embedding_index/d_model)\n",
    "        \n",
    "        # First column has values from sine function and second column has values from cos function\n",
    "        pe[:, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 1::2] = torch.cos(position*div_term)\n",
    "        \n",
    "        self.register_buffer('pe',pe)\n",
    "        \n",
    "    def forward(self, word_embeddings):\n",
    "        # Adds word_embeddings and position embeddings\n",
    "        return word_embeddings + self.pe[:word_embeddings.size(0),:]\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8258a",
   "metadata": {},
   "source": [
    "### Self-Attention\n",
    "\n",
    "Calculate: Query, Key, Value Matrices\n",
    "\n",
    "**Query Weights**: Weights that were used to create Query Matrix\n",
    "\n",
    "Word_Embedding + Position Encodings x **Query Weights**\n",
    "\n",
    "**Key Weights**: Weights that were used to create Key Matrix\n",
    "\n",
    "Word_Embedding + Position Encodings x **Key Weights**\n",
    "\n",
    "**Value Weights**: Weights that were used to create Value Matrix\n",
    "\n",
    "Word_Embedding + Position Encodings x **Value Weights**\n",
    "\n",
    "\n",
    "\n"
    "![We only build the decoder aspect](https://media.licdn.com/dms/image/D4D12AQHhadKJt_C9Nw/article-cover_image-shrink_720_1280/0/1691650944311?e=2147483647&v=beta&t=FtQjxZTQrJpU7UCosIIw_rsFa92l3i6RzDR2vYDfYm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d773bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=2):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, q_input, k_input, v_input, mask=None):\n",
    "        q = self.W_q(q_input)\n",
    "        k = self.W_k(k_input)\n",
    "        v = self.W_v(v_input)\n",
    "\n",
    "        sims = torch.matmul(q, k.transpose(-2, -1))  # [batch, seq, seq]\n",
    "        scaled_sims = sims / (k.size(-1) ** 0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_sims = scaled_sims.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        attention_weights = F.softmax(scaled_sims, dim=-1)\n",
    "        output = torch.matmul(attention_weights, v)  # weighted sum of values\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2fd1c",
   "metadata": {},
   "source": [
    "### Decoder Only Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "382b034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderOnlyTransformer(L.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_tokens, d_model=2,max_len=6):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n",
    "        self.pe = PositionEncoding(d_model=d_model,max_len = max_len)\n",
    "        \n",
    "        self.self_attention = Attention(d_model=d_model)\n",
    "        # Fully Connected Linear Layer\n",
    "        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    def forward(self, token_ids):\n",
    "        # Convert to Word Embeddings:\n",
    "        word_embeddings = self.we(token_ids)\n",
    "        # Create Position Encodings:\n",
    "        position_encoded = self.pe(word_embeddings)\n",
    "        \n",
    "        # Lower Triangle ones matrix\n",
    "        mask = torch.tril(torch.ones( (token_ids.size(dim=0)), token_ids.size(dim=0)))\n",
    "        \n",
    "        # Convert to a True/False Matrix\n",
    "        mask = mask == 0\n",
    "        \n",
    "        self_attention_values = self.self_attention(position_encoded,position_encoded, position_encoded,mask=mask)\n",
    "        \n",
    "        # Residual Connection\n",
    "        residual_connection_values = position_encoded + self_attention_values\n",
    "        \n",
    "        fc_layer_output = self.fc_layer(residual_connection_values)\n",
    "        \n",
    "        return fc_layer_output\n",
    "        \n",
    "        \n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7e72d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "38c95e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecoderOnlyTransformer(num_tokens=len(token_to_id), d_model=2, max_len=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3452b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Predicted Tokens:\n",
      "\n",
      "\t the\n",
      "\t OAT\n",
      "\t James\n"
     ]
    }
   ],
   "source": [
    "model_input = torch.tensor([\n",
    "    token_to_id[\"Lebron\"], \n",
    "    token_to_id[\"James\"], \n",
    "    token_to_id[\"is\"], \n",
    "    token_to_id[\"the\"], \n",
    "    token_to_id[\"Greatest\"], \n",
    "    token_to_id[\"<EOS>\"]\n",
    "])\n",
    "\n",
    "input_length = model_input.size(dim=0)\n",
    "predictions = model(model_input)\n",
    "\n",
    "predicted_id = torch.tensor([torch.argmax(predictions[-1, :])])\n",
    "predicted_ids = predicted_id\n",
    "\n",
    "max_length = 8\n",
    "\n",
    "print(input_length)\n",
    "for i in range(input_length, max_length):\n",
    "    #if predicted_id == token_to_id[\"<EOS>\"]:\n",
    "     #   break\n",
    "\n",
    "    model_input = torch.cat((model_input, predicted_id))\n",
    "    predictions = model(model_input)\n",
    "    predicted_id = torch.tensor([torch.argmax(predictions[-1, :])])\n",
    "    predicted_ids = torch.cat((predicted_ids, predicted_id))\n",
    "\n",
    "print(\"Predicted Tokens:\\n\")\n",
    "for id in predicted_ids:\n",
    "    print(\"\\t\", id_to_token[id.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b490fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
